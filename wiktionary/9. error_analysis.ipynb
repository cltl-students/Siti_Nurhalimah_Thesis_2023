{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dfff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d32ae4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tsv_files(tsv_file1, tsv_file2, output_file):\n",
    "    \"\"\"\n",
    "    Function to merge the dataframes from both files based on the common columns.\n",
    "    Param:\n",
    "        tsv_file1 (str): Path to the first TSV file to be merged.\n",
    "        tsv_file2 (str): Path to the second TSV file to be merged.\n",
    "        output_file (str): Path to the output TSV file where the merged data will be saved.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df1 = pd.read_csv(tsv_file1, sep='\\t')\n",
    "    df2 = pd.read_csv(tsv_file2, sep='\\t')\n",
    "\n",
    "    merged_df = pd.merge(df1, df2[['synset', 'lemma', 'annotation', 'prediction label']], on=['synset', 'lemma', 'annotation'], how='left')\n",
    "    merged_df.to_csv(output_file, sep='\\t', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tsv_file1 = './data/merged_file_wiktionary.tsv'\n",
    "    tsv_file2 = './predictions_results/wiktionary_condition_five.tsv'\n",
    "    output_file = \"./data/error_analysis_wiktionary.tsv\"\n",
    "\n",
    "    merge_tsv_files(tsv_file1, tsv_file2, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "71c64789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    }
   ],
   "source": [
    "file_path = './data/error_analysis_wiktionary.tsv'\n",
    "\n",
    "df = pd.read_csv(file_path, delimiter='\\t')\n",
    "filtered_rows = []\n",
    "for index, row in df.iterrows():\n",
    "    annotation = row['annotation']\n",
    "    prediction = row['prediction label']\n",
    "    goodness_label = row['goodness label']\n",
    "    language = row['language']\n",
    "    confidence = row['confidence']\n",
    "\n",
    "    if annotation == 'DELETE' and prediction == 'KEEP' and confidence == 'None' and language == 'None' :\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "result_df = pd.DataFrame(filtered_rows)\n",
    "\n",
    "print(len(result_df))\n",
    "\n",
    "# Total = 958\n",
    "#confidence 1 = 697\n",
    "\n",
    "# Arabic: 48\n",
    "# Croatian: 0\n",
    "# Thai: 1\n",
    "# Slovene: 51\n",
    "# Finnish: 252\n",
    "# Portuguese: 62\n",
    "# Japanese: 24\n",
    "# Polish: 11\n",
    "# Greek: 19\n",
    "# Mandarin Chinese: 15\n",
    "# English: 116\n",
    "# Spanish: 87\n",
    "#None: 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b131c2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "958\n",
      "Total: 958\n",
      "Confidence 1: 0\n",
      "Portuguese: 62\n",
      "Finnish: 252\n",
      "None: 110\n",
      "Portuguese, Spanish: 27\n",
      "Arabic: 48\n",
      "English: 116\n",
      "Spanish: 87\n",
      "Spanish, Finnish: 19\n",
      "Finnish, English: 12\n",
      "Portuguese, Finnish, Thai, Japanese: 4\n",
      "Japanese: 24\n",
      "Polish, English: 9\n",
      "Greek, English: 13\n",
      "Slovene: 51\n",
      "Greek: 19\n",
      "Portuguese, English: 8\n",
      "Serbo-Croatian: 11\n",
      "Polish: 11\n",
      "Mandarin Chinese: 15\n",
      "Finnish, Japanese: 5\n",
      "Greek, Finnish: 5\n",
      "Portuguese, Spanish, English: 6\n",
      "Mandarin Chinese, Thai: 6\n",
      "Portuguese, Finnish: 2\n",
      "Polish, Finnish, English, Japanese: 1\n",
      "Slovene, Spanish, Greek, Finnish, Portuguese, Mandarin Chinese, English, Serbo-Croatian: 3\n",
      "Thai: 1\n",
      "Polish, Japanese, Finnish, Portuguese, English: 1\n",
      "Greek, Finnish, English, Serbo-Croatian: 2\n",
      "Spanish, Japanese, Finnish, Portuguese, English: 5\n",
      "Portuguese, Finnish, English: 2\n",
      "English, Thai: 2\n",
      "Slovene, Finnish, English: 3\n",
      "Slovene, Spanish, Polish, Japanese, Greek, Finnish, Thai, Portuguese, Mandarin Chinese: 1\n",
      "Slovene, Spanish, Polish, Greek, Portuguese, English: 1\n",
      "Portuguese, English, Thai, Japanese: 3\n",
      "Spanish, English: 2\n",
      "Slovene, Spanish, Greek, Thai, Portuguese, Mandarin Chinese, English: 2\n",
      "Portuguese, Greek, Finnish, English: 1\n",
      "Polish, Arabic: 1\n",
      "Finnish, Thai: 1\n",
      "Finnish, English, Japanese: 1\n",
      "Portuguese, Finnish, English, Spanish: 1\n",
      "Portuguese, Slovene: 1\n",
      "Portuguese, Polish: 1\n"
     ]
    }
   ],
   "source": [
    "file_path = './data/error_analysis_wiktionary.tsv'\n",
    "df = pd.read_csv(file_path, delimiter='\\t')\n",
    "filtered_rows = []\n",
    "language_counts = {}\n",
    "for index, row in df.iterrows():\n",
    "    annotation = row['annotation']\n",
    "    prediction = row['prediction label']\n",
    "    goodness_label = row['goodness label']\n",
    "    language = row['language']\n",
    "    confidence = row['confidence']\n",
    "    \n",
    "    if annotation == 'DELETE' and prediction == 'KEEP' :\n",
    "        filtered_rows.append(row)\n",
    "        if language in language_counts:\n",
    "            language_counts[language] += 1\n",
    "        else:\n",
    "            language_counts[language] = 1\n",
    "\n",
    "result_df = pd.DataFrame(filtered_rows)\n",
    "\n",
    "print(len(result_df))\n",
    "print(\"Total:\", len(result_df))\n",
    "print(\"Confidence 1:\", len(result_df[result_df['confidence'] == 1]))\n",
    "\n",
    "for language, count in language_counts.items():\n",
    "        print(f\"{language}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "191e11a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "958\n",
      "Total: 958\n",
      "Confidence 1: 697\n",
      "Portuguese: 62\n",
      "Finnish: 252\n",
      "None: 110\n",
      "Portuguese, Spanish: 27\n",
      "Arabic: 48\n",
      "English: 116\n",
      "Spanish: 87\n",
      "Spanish, Finnish: 19\n",
      "Finnish, English: 12\n",
      "Portuguese, Finnish, Thai, Japanese: 4\n",
      "Japanese: 24\n",
      "Polish, English: 9\n",
      "Greek, English: 13\n",
      "Slovene: 51\n",
      "Greek: 19\n",
      "Portuguese, English: 8\n",
      "Serbo-Croatian: 11\n",
      "Polish: 11\n",
      "Mandarin Chinese: 15\n",
      "Finnish, Japanese: 5\n",
      "Greek, Finnish: 5\n",
      "Portuguese, Spanish, English: 6\n",
      "Mandarin Chinese, Thai: 6\n",
      "Portuguese, Finnish: 2\n",
      "Polish, Finnish, English, Japanese: 1\n",
      "Slovene, Spanish, Greek, Finnish, Portuguese, Mandarin Chinese, English, Serbo-Croatian: 3\n",
      "Thai: 1\n",
      "Polish, Japanese, Finnish, Portuguese, English: 1\n",
      "Greek, Finnish, English, Serbo-Croatian: 2\n",
      "Spanish, Japanese, Finnish, Portuguese, English: 5\n",
      "Portuguese, Finnish, English: 2\n",
      "English, Thai: 2\n",
      "Slovene, Finnish, English: 3\n",
      "Slovene, Spanish, Polish, Japanese, Greek, Finnish, Thai, Portuguese, Mandarin Chinese: 1\n",
      "Slovene, Spanish, Polish, Greek, Portuguese, English: 1\n",
      "Portuguese, English, Thai, Japanese: 3\n",
      "Spanish, English: 2\n",
      "Slovene, Spanish, Greek, Thai, Portuguese, Mandarin Chinese, English: 2\n",
      "Portuguese, Greek, Finnish, English: 1\n",
      "Polish, Arabic: 1\n",
      "Finnish, Thai: 1\n",
      "Finnish, English, Japanese: 1\n",
      "Portuguese, Finnish, English, Spanish: 1\n",
      "Portuguese, Slovene: 1\n",
      "Portuguese, Polish: 1\n",
      "Others: 12\n"
     ]
    }
   ],
   "source": [
    "file_path = './data/error_analysis_wiktionary.tsv'\n",
    "df = pd.read_csv(file_path, delimiter='\\t')\n",
    "filtered_rows = []\n",
    "language_counts = {}\n",
    "\n",
    "other_count = 0\n",
    "for index, row in df.iterrows():\n",
    "    annotation = row['annotation']\n",
    "    prediction = row['prediction label']\n",
    "    goodness_label = row['goodness label']\n",
    "    language = row['language']\n",
    "    confidence = row['confidence']\n",
    "\n",
    "    if annotation == 'DELETE' and prediction == 'KEEP' :\n",
    "        filtered_rows.append(row)\n",
    "        if language in language_counts:\n",
    "            language_counts[language] += 1\n",
    "        else:\n",
    "            language_counts[language] = 1\n",
    "\n",
    "for language, count in language_counts.items():\n",
    "    if count == 1:\n",
    "        other_count += 1\n",
    "\n",
    "result_df = pd.DataFrame(filtered_rows)\n",
    "\n",
    "if other_count != '!':\n",
    "    language_counts['Others'] = other_count\n",
    "\n",
    "print(len(result_df))\n",
    "print(\"Total:\", len(result_df))\n",
    "print(\"Confidence 1:\", len(result_df[result_df['confidence'] == '1']))\n",
    "\n",
    "for language, count in language_counts.items():\n",
    "    print(f\"{language}: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
