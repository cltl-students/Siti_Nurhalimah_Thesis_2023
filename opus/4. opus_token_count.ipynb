{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dedab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c409c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines: 318548\n"
     ]
    }
   ],
   "source": [
    "filename = './data/output_opus.tsv'\n",
    "line_count = 0\n",
    "\n",
    "with open(filename, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file, delimiter='\\t')\n",
    "    line_count = sum(1 for _ in reader) - 1\n",
    "\n",
    "print(\"Number of lines:\", line_count) \n",
    "\n",
    "#318,548 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f8083b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total = 1,269,248\n",
      "Indonesian = 318,547\n",
      "English = 128,287\n",
      "Polish = 120,430\n",
      "Portuguese = 108,342\n",
      "Spanish = 102,352\n",
      "Slovene = 91,884\n",
      "Greek = 90,941\n",
      "Finnish = 90,188\n",
      "Croatian = 88,364\n",
      "Arabic = 86,656\n",
      "Japanese = 26,536\n",
      "Thai = 8,564\n",
      "Chinese = 8,157\n"
     ]
    }
   ],
   "source": [
    "def count_tokens_per_language(file_path):\n",
    "    \"\"\"\n",
    "    Function to count the number of tokens per language in a TSV file.\n",
    "\n",
    "    Param:\n",
    "        file_path (str): Path to the input TSV file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing language-wise token counts, with 'Total' representing the overall count.\n",
    "    \"\"\"\n",
    "    token_counts = {}\n",
    "    total_count = 0  # Initialize total count\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as tsv_file:\n",
    "        reader = csv.reader(tsv_file, delimiter='\\t')\n",
    "        header = next(reader)  \n",
    "\n",
    "        for row in reader:\n",
    "            for language, token in zip(header, row):\n",
    "                if token != 'None':\n",
    "                    token_counts[language] = token_counts.get(language, 0) + 1\n",
    "                    total_count += 1  \n",
    "\n",
    "    token_counts['Total'] = total_count\n",
    "\n",
    "    return token_counts\n",
    "\n",
    "\n",
    "file_path = './data/output_opus.tsv'\n",
    "results = count_tokens_per_language(file_path)\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for language, count in sorted_results:\n",
    "    count_str = f\"{count:,}\"\n",
    "    print(f\"{language} = {count_str}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
