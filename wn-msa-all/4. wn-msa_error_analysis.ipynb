{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96b54653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581f8a4",
   "metadata": {},
   "source": [
    "## Match Wiktionary data with the main file (wn_msa_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0c2cc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSV files merged and saved as: ./data/wn_msa_wiktionary.tsv\n"
     ]
    }
   ],
   "source": [
    "def merge_tsv(tsv_file1, tsv_file2, output_file):\n",
    "    \"\"\"\n",
    "    Function to merge the dataframes from both files based on the common columns.\n",
    "    Param:\n",
    "        tsv_file1 (str): Path to the first TSV file to be merged.\n",
    "        tsv_file2 (str): Path to the second TSV file to be merged.\n",
    "        output_file (str): Path to the output TSV file where the merged data will be saved.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    merged_rows = []\n",
    "\n",
    "    with open(tsv_file1, 'r', encoding='utf-8') as file1, open(tsv_file2, 'r', encoding='utf-8') as file2:\n",
    "        reader1 = csv.DictReader(file1, delimiter='\\t')\n",
    "        reader2 = csv.DictReader(file2, delimiter='\\t')\n",
    "        \n",
    "        # Create a dictionary to store rows from tsv_file1 for quick lookup\n",
    "        tsv1_rows = {row['synset']: row for row in reader1}\n",
    "        for row2 in reader2:\n",
    "            synset = row2['synset']\n",
    "            if synset in tsv1_rows:\n",
    "                row1 = tsv1_rows[synset]\n",
    "                confidence = int(row1['count'])\n",
    "                language = row1['language']\n",
    "            else:\n",
    "                confidence = 'None'\n",
    "                language = 'None'\n",
    "            merged_row = {\n",
    "                'synset': synset,\n",
    "                'lemma': row2['lemma'],\n",
    "                'goodness label': row2['label'],\n",
    "                'confidence': confidence,\n",
    "                'language': language\n",
    "            }\n",
    "            merged_rows.append(merged_row)\n",
    "\n",
    "    fieldnames = ['synset', 'lemma', 'goodness label', 'confidence', 'language']\n",
    "    with open(output_file, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames, delimiter='\\t')\n",
    "        writer.writeheader()\n",
    "        writer.writerows(merged_rows)\n",
    "\n",
    "tsv_file1 = './data/synset_output_wiktionary_with_labels.tsv'\n",
    "tsv_file2 = './data/wn_msa_data.tsv'\n",
    "output_file = './data/wn_msa_wiktionary.tsv'\n",
    "\n",
    "merge_tsv(tsv_file1, tsv_file2, output_file)\n",
    "print(\"TSV files merged and saved as:\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773c1dce",
   "metadata": {},
   "source": [
    "# Run the Wiktionary data on the main data with the system's best condition to generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c767e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction labels saved to './predictions_results/wn-msa-wiktionary.tsv' successfully.\n"
     ]
    }
   ],
   "source": [
    "def process_synsets(input_tsv_path, output_tsv_path, threshold):\n",
    "    \"\"\"\n",
    "    Function to process a TSV file, assigning prediction labels based on given criteria.\n",
    "    Param:\n",
    "        input_tsv_path (str): Path to the input TSV file.\n",
    "        output_tsv_path (str): Path to the output TSV file.\n",
    "        threshold (str): Threshold value for prediction label assignment.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(input_tsv_path, 'r', encoding='utf-8') as tsv_file:\n",
    "        reader = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "        rows = list(reader)\n",
    "\n",
    "    with open(output_tsv_path, 'w', newline='', encoding='utf-8') as tsv_file:\n",
    "        writer = csv.writer(tsv_file, delimiter='\\t')\n",
    "        writer.writerow(['synset', 'lemma', 'prediction label'])\n",
    "\n",
    "        for row in rows:\n",
    "            synset = row['synset']\n",
    "            lemma = row['lemma']\n",
    "            goodness_label = row['goodness label']\n",
    "            confidence_score = row['confidence']\n",
    "            language = row['language']\n",
    "            \n",
    "            label = assign_label(synset, confidence_score, language, goodness_label, int(threshold))\n",
    "            writer.writerow([synset, lemma, label])\n",
    "\n",
    "    print(f\"Prediction labels saved to '{output_tsv_path}' successfully.\")\n",
    "    \n",
    "## Condition 5\n",
    "def assign_label(synset, confidence_score, language, goodness_label, threshold):\n",
    "    \"\"\"\n",
    "    Function to assign a label to a synset based on given criteria.\n",
    "\n",
    "    Param:\n",
    "        synset (str): The synset to be labeled.\n",
    "        confidence_score (float): The confidence score associated with the synset.\n",
    "        language (str): The language of the synset.\n",
    "        goodness_label (str): The goodness label associated with the synset.\n",
    "        threshold (str): The threshold value used for comparison with confidence_score.\n",
    "\n",
    "    Returns:\n",
    "        str: The label assigned to the synset based on the predefined condition.\n",
    "    \"\"\"\n",
    "    if goodness_label == 'O' and synset.endswith('-v') and confidence_score == '1' and language == 'English':\n",
    "        return 'DELETE'\n",
    "    elif goodness_label == 'X' and synset.endswith('-v') and confidence_score == '1' and language == 'English':\n",
    "        return 'DELETE'\n",
    "    else:\n",
    "        return 'KEEP'\n",
    "\n",
    "\n",
    "input_tsv_path = './data/wn_msa_wiktionary.tsv'\n",
    "output_tsv_path = './predictions_results/wn-msa-wiktionary.tsv'\n",
    "threshold = '1'\n",
    "process_synsets(input_tsv_path, output_tsv_path, threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a400889c",
   "metadata": {},
   "source": [
    "## Match OPUS data with the main file (wn_msa_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d01dd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSV files merged and saved as: ./data/wn_msa_opus.tsv\n"
     ]
    }
   ],
   "source": [
    "def merge_tsv(tsv_file1, tsv_file2, output_file):\n",
    "    \"\"\"\n",
    "    Function to merge the dataframes from both files based on the common columns.\n",
    "    Param:\n",
    "        tsv_file1 (str): Path to the first TSV file to be merged.\n",
    "        tsv_file2 (str): Path to the second TSV file to be merged.\n",
    "        output_file (str): Path to the output TSV file where the merged data will be saved.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    merged_rows = []\n",
    "\n",
    "    with open(tsv_file1, 'r', encoding='utf-8') as file1, open(tsv_file2, 'r', encoding='utf-8') as file2:\n",
    "        reader1 = csv.DictReader(file1, delimiter='\\t')\n",
    "        reader2 = csv.DictReader(file2, delimiter='\\t')\n",
    "        \n",
    "        # Create a dictionary to store rows from tsv_file1 for quick lookup\n",
    "        tsv1_rows = {row['synset']: row for row in reader1}\n",
    "\n",
    "        for row2 in reader2:\n",
    "            synset = row2['synset']\n",
    "            if synset in tsv1_rows:\n",
    "                row1 = tsv1_rows[synset]\n",
    "                confidence = int(row1['count'])\n",
    "                language = row1['language']\n",
    "            else:\n",
    "                confidence = 'None'\n",
    "                language = 'None'\n",
    "\n",
    "            merged_row = {\n",
    "                'synset': synset,\n",
    "                'lemma': row2['lemma'],\n",
    "                'goodness label': row2['label'],\n",
    "                'confidence': confidence,\n",
    "                'language': language\n",
    "            }\n",
    "            merged_rows.append(merged_row)\n",
    "\n",
    "    fieldnames = ['synset', 'lemma', 'goodness label', 'confidence', 'language']\n",
    "    with open(output_file, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames, delimiter='\\t')\n",
    "        writer.writeheader()\n",
    "        writer.writerows(merged_rows)\n",
    "\n",
    "\n",
    "tsv_file1 = './data/synset_output_opus_with_labels.tsv'\n",
    "tsv_file2 = './data/wn_msa_data.tsv'\n",
    "output_file = './data/wn_msa_opus.tsv'\n",
    "\n",
    "merge_tsv(tsv_file1, tsv_file2, output_file)\n",
    "print(\"TSV files merged and saved as:\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c868f75",
   "metadata": {},
   "source": [
    "# Run the OPUS data on the main data with the system's best condition to generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b0c6367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction labels saved to './predictions_results/wn-msa-opus.tsv' successfully.\n"
     ]
    }
   ],
   "source": [
    "def process_synsets(input_tsv_path, output_tsv_path, threshold):\n",
    "    \"\"\"\n",
    "    Function to process a TSV file, assigning prediction labels based on given criteria.\n",
    "    Param:\n",
    "        input_tsv_path (str): Path to the input TSV file.\n",
    "        output_tsv_path (str): Path to the output TSV file.\n",
    "        threshold (str): Threshold value for prediction label assignment.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(input_tsv_path, 'r', encoding='utf-8') as tsv_file:\n",
    "        reader = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "        rows = list(reader)\n",
    "\n",
    "    with open(output_tsv_path, 'w', newline='', encoding='utf-8') as tsv_file:\n",
    "        writer = csv.writer(tsv_file, delimiter='\\t')\n",
    "        writer.writerow(['synset', 'lemma', 'prediction label'])\n",
    "\n",
    "        for row in rows:\n",
    "            synset = row['synset']\n",
    "            lemma = row['lemma']\n",
    "            goodness_label = row['goodness label']\n",
    "            confidence_score = row['confidence']\n",
    "            language = row['language']\n",
    "            \n",
    "            label = assign_label(synset, confidence_score, language, goodness_label, int(threshold))\n",
    "            writer.writerow([synset, lemma, label])\n",
    "\n",
    "    print(f\"Prediction labels saved to '{output_tsv_path}' successfully.\")\n",
    "    \n",
    "## Condition 5\n",
    "def assign_label(synset, confidence_score, language, goodness_label, threshold):\n",
    "    if goodness_label == 'O' and synset.endswith('-v') and confidence_score == '1' and language == 'English':\n",
    "        return 'DELETE'\n",
    "    elif goodness_label == 'X' and synset.endswith('-v') and confidence_score == '1' and language == 'English':\n",
    "        return 'DELETE'\n",
    "    else:\n",
    "        return 'KEEP'\n",
    "\n",
    "\n",
    "input_tsv_path = './data/wn_msa_opus.tsv'\n",
    "output_tsv_path = './predictions_results/wn-msa-opus.tsv'\n",
    "threshold = '1'\n",
    "process_synsets(input_tsv_path, output_tsv_path, threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133da97d",
   "metadata": {},
   "source": [
    "# Taking random sampling for hand-checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f1c15ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling and saving successful for Wiktionary!\n",
      "Sampling and saving successful for OPUS!\n"
     ]
    }
   ],
   "source": [
    "## Wiktionary\n",
    "\n",
    "input_tsv_path = './predictions_results/wn-msa-wiktionary.tsv'\n",
    "output_tsv_path = './predictions_results/msa-wiktionary-150-random-sample.tsv'\n",
    "\n",
    "df = pd.read_csv(input_tsv_path, delimiter=\"\\t\")\n",
    "\n",
    "# Take a random sample of 150 rows\n",
    "sampled_df = df.sample(n=150, random_state=42, replace=True)  \n",
    "\n",
    "# Write the sampled data to a new TSV file\n",
    "sampled_df.to_csv(output_tsv_path, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Sampling and saving successful for Wiktionary!\")\n",
    "\n",
    "\n",
    "## OPUS\n",
    "input_tsv_path = './predictions_results/wn-msa-opus.tsv'\n",
    "output_tsv_path = './predictions_results/msa-opus-150-random-sample.tsv'\n",
    "\n",
    "df = pd.read_csv(input_tsv_path, delimiter=\"\\t\")\n",
    "\n",
    "# Take a random sample of 150 rows\n",
    "sampled_df = df.sample(n=150, random_state=42, replace=True)\n",
    "\n",
    "# Write the sampled data to a new TSV file\n",
    "sampled_df.to_csv(output_tsv_path, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Sampling and saving successful for OPUS!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e717e9c",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2534f429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines: 641030\n",
      "Number of KEEP predictions: 584688\n",
      "Number of DELETE predictions: 56342\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters\n",
    "total_lines = 0\n",
    "keep_count = 0\n",
    "delete_count = 0\n",
    "\n",
    "# Change to wiktionary path too for the second predictions\n",
    "file_path = \"./predictions_results/wn-msa-opus.tsv\"\n",
    "\n",
    "try:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        next(file)\n",
    "        for line in file:\n",
    "            total_lines += 1\n",
    "            _, _, prediction_label = line.strip().split(\"\\t\")\n",
    "            \n",
    "            # Count the occurrences of \"KEEP\" and \"DELETE\"\n",
    "            if prediction_label == \"KEEP\":\n",
    "                keep_count += 1\n",
    "            elif prediction_label == \"DELETE\":\n",
    "                delete_count += 1\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please provide the correct file path.\")\n",
    "    exit(1)\n",
    "\n",
    "print(\"Total lines:\", total_lines)\n",
    "print(\"Number of KEEP predictions:\", keep_count)\n",
    "print(\"Number of DELETE predictions:\", delete_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
